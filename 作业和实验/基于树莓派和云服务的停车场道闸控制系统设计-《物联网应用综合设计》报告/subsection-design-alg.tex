HyperLPR的车牌识别使用的是模板匹配法。该方法对车牌图像要求较高，当车牌倾斜角度很小、边框去除干净、图像噪声较少，字符尺寸和字符间距比较标准时，该算法速度快、分割效果好；而当车牌图像质量较为一般时，该算法的分割效果常常不尽人意。因此在进行车牌识别前需要准确定位图像中的车牌位置，并对车牌字符进行准确分割。

\subsubsection{车牌粗定位}
车牌定位的方法有很多种，在学术界它其实是属于场景文字检测的一种特定情况。
\begin{itemize}
	\item 考虑到字符间垂直边缘比较密集，有基于边缘的方法；
	\item 考虑到字符个体间的特征，有基于个体字符特征的方法；
	\item 考虑到车牌这种共性特征比较强烈的目标 ，有基于目标检测的方法。
\end{itemize}
HyperLPR用了使用了基于目标检测的方法进行车牌粗定位，其使用的目标检测器是基于OpenCV的Haar级联分类器，该分类器使用OpenALPR的Train-Detector进行训练，使用4700张正样本和12000张负样本。正样本通过手动crop或者使用easypr或HyperLPR的crop模块进行裁剪。对于负样本，在train detector目录下已经包含了一些基本的负样本，但是在多次训练后发现，使用这些负样本训练出来的检测器在垂直边缘密集的地方误检特别高，因此改用类似于Hard Sample Mining的策略，将这些部分的误检区域裁剪出来，加入到分类器的训练当中。

使用目标检测器进行粗定位的过程比较简单，在opencv中只需要调用CascadeClassifier进行多尺度检测即可。

\subsubsection{车牌精定位}
HyperLPR使用类似于MSER的方式的多级二值化+RANSAC拟合车牌的上下边界。下面是该过程的大致步骤。
在训练完cascade分类器之后就会，haar adaboost cascade目标检测只能输出三个参数：目标的x 、目标的y 、目标的尺度。

也就是说我们不像DPM和现代目标检测那样可以输出目标的长宽比。所以光凭这三个参数还远远不够，在车牌有角度的倾斜的情况下。与传统目标检测不同的是，HyperLPR更需要确定车牌精确的位置。这里HyperLPR尝试了很多种做法包括直接对ROI区域进行Regression的方法，在少量的测试结果来看并不能取得良好的效果。最后HyperLPR想出了一种较为简单粗暴的精定位算法。

首先为了最大程度的保留车牌图像，对cascade目标检测后的区域进行扩展。在扩展后矩形中做文章。

在完成对cascade目标检测后的区域进行扩展的操作之后，接着使用多个参数对这个区域进行多次自适应二值化，即对opencv中adaptiveThreshold函数的k的参数从选择从-50变化到0。做15次二值化，对每次二值化的图像进行连通域分析寻找满足字符长宽比的轮廓并找出对应的矩形框。将矩形框对角线的两个顶点找出来，进而对下面的点做直线拟合。在做直线拟合之前，这里要特别介绍一下随机抽样一致(RANSAC)算法。

在实际应用中获取到的数据，常常会包含有噪声数据，这些噪声数据会使对模型的构建造成干扰，我们称这样的噪声数据点为outliers，那些对于模型构建起积极作用的我们称它们为inliers，RANSAC做的一件事就是先随机的选取一些点，用这些点去获得一个模型(这个讲得有点玄，如果是在做直线拟合的话，这个所谓的模型其实就是斜率)，然后用此模型去测试剩余的点，如果测试的数据点在误差允许的范围内，则将该数据点判为inlier，否则判为outlier。inliers的数目如果达到了某个设定的阈值，则说明此次选取的这些数据点集达到了可以接受的程度，否则继续前面的随机选取点集后所有的步骤，不断重复此过程，直到找到选取的这些数据点集达到了可以接受的程度为止，此时得到的模型便可认为是对数据点的最优模型构建。

由于在做连通域分析的时候，我们仅仅使用满足字符长宽比例boundingbox作为判断条件，所以会带来一定的噪声。RANSAC算法能帮助我们剔除这些噪声点。
使用RANSAC算法对之前找出的点进行拟合，这样就找到了上边界和下边界。

在此基础上使用CNN Regression算法来确定车牌的左右边界。最后只需要对此区域进行裁剪即可。

这样就完成了车牌的精定位。

\subsubsection{车牌倾斜校正}
目前稳定可靠的文字倾斜检测主要有Radon 变换和 Hough 变换两种，不过这两种算法的时间复杂度都在$O(n^3)$级别。这种方法往往需要大量数值运算，在文字大量出现的图片显得效率低下力不从心。

因此HyperLPR使用了基于方向纹理场的算法进行车牌校正倾斜。该算法是受lsd直线检测算法的启发，发现可以统计各个方向场的角度来寻找图像中纹理最为密集的两个方向。主要计算公式如公式(\ref{eq:HyperLPR})，其运行步骤如下：
\begin{enumerate}
	\item 将图像划分为不重叠的子块(16×16)；
	\item 利用Sobel算子计算每个子块像素点的梯度值；
	\item 利用公式(\ref{eq:HyperLPR})计算中心点在$(i,j)$的子块的脊线的方向；
	\item 以$(1/\pi)$为bin统计各个块方向的直方图；
	\item 使用高斯滤波进行核密度的估计（平滑）；
	\item 选取在两个区间的极大值作为校正方向。
\end{enumerate}

\begin{equation}\label{eq:HyperLPR}
	\begin{split}
		V_x(i,j)&=\sum_{u=i-w/2}^{i+w/2}\sum_{v=j-w/2}^{j+w/2}2\partial_x(u,v)\partial_y(u,v)\\
		V_y(i,j)&=\sum_{u=i-w/2}^{i+w/2}\sum_{v=j-w/2}^{j+w/2}\partial^2_x(u,v)\partial^2_y(u,v)\\
		\theta(i,j)&=\frac{1}{2}tan^{-1}(\frac{V_y(i,j)}{V_x(i,j)})
	\end{split}
\end{equation}

\subsubsection{字符识别}
模板匹配法根据车牌的标准样式，结合字符的结构、尺寸和间距特征，设计出一个固定的模板和一个用来度量模板匹配程度的评价函数，然后将该模板在归一化后的图像中从左至右滑动，每滑动一次计算对应的评价值，最终选出匹配程度最高的模板滑动位置作为字符分割的位置，并以此模板对应的字符作为当前位置的字符识别结果。
